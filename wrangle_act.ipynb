{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gathering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import requests\n",
    "import numpy as np\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# load twitter_archive_enhanced into a dataframe,tae stands for twitter archive enhanced\n",
    "tae=pd.read_csv('twitter-archive-enhanced.csv')\n",
    "url = 'https://raw.githubusercontent.com/udacity/new-dand-advanced-china/master/数据清洗/WeRateDogs项目/image-predictions.tsv'\n",
    "response = requests.get(url)\n",
    "\n",
    "#open a file called image-predictions.tsv, and write response in this file\n",
    "with open(url.split('/')[-1],mode='wb') as file:\n",
    "    file.write(response.content)\n",
    "    \n",
    "# ip stands for image prediction\n",
    "ip = pd.read_csv('image-predictions.tsv',sep='\\t')\n",
    "tweet_json = []\n",
    "\n",
    "#read tweet_json file, and put content in a dataframe\n",
    "with open('tweet_json.txt', 'r') as f:\n",
    "    for line in f.readlines():\n",
    "        x = json.loads(line)\n",
    "        tweet_id=x['id']\n",
    "        retweet_count = x['retweet_count']\n",
    "        favorite_count = x['favorite_count']\n",
    "        tweet_json.append({'tweet_id':tweet_id,\n",
    "                          'retweet_count':retweet_count,\n",
    "                          'favorite_count':favorite_count})\n",
    "print(tweet_json)\n",
    "# turn into a dataframe\n",
    "tweet = pd.DataFrame(tweet_json, columns=['tweet_id','retweet_count','favorite_count'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Assessing Twitter archive enhanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tae.info() # 181 retweet_id\n",
    "tae.sample(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tae['name'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tae.rating_denominator.value_counts()\n",
    "ip.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### assessing image predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ip.sample(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ip.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ip['p1_dog'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test the p2 results\n",
    "(ip.p2_dog == False).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test the p3 results\n",
    "(ip.p3_dog == False).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test the result of all three pictures are not dogs\n",
    "ip[(ip['p1_dog']==False) & (ip['p2_dog']==False) & (ip['p3_dog']==False)].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quality\n",
    "\n",
    "#### data type of \"time stamp\"should be datetime\n",
    "#### in_reply_to_status_id and in_reply_to_user_id have many missing values\n",
    "#### twitter_archive_enhanced, 181 rows belong to retweet\n",
    "#### doggo，floofer ，pupper，puppo have missing values\n",
    "#### twitter_archive_enhanced, change non-sense dogs names to none.\n",
    "#### image prediction:get rid of pics that are not dogs（p1,p2,p3 are all false）\n",
    "#### image: unstandarized naming for dogs, namely: some are lower case, some have first letters of the name that are in upper case, underscore and space are used interchangeably. \n",
    "#### some denominators could be divided by 10，and some numerators can also divided by N\n",
    "\n",
    "\n",
    "# Tidiness\n",
    "#### can combine the statuse column\n",
    "####  all three data sets are collected based on tweet_id, so we can combine these three data sets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make copies of original dataframes\n",
    "tae_clean = tae.copy()\n",
    "ip_clean = ip.copy()\n",
    "tweet_clean = tweet.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Issue 1\n",
    "\n",
    "<p> we only care about original tweets，so we exclude the row of 'retweeted_status_x',and data related to in reply</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#delete retweet status，as we want to focus on the original tweets\n",
    "tae_clean.drop(tae_clean[tae_clean.retweeted_status_id.notnull()].index, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop retweets , in_reply_to_status_id , in_reply_to_user_id\n",
    "tae_clean.drop(['retweeted_status_id',\n",
    "                     'retweeted_status_user_id',\n",
    "                     'retweeted_status_timestamp',\n",
    "                     'in_reply_to_status_id',\n",
    "                     'in_reply_to_user_id'], axis=1, inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tae_clean.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Issue 2\n",
    "<p> doggo，floofer ，pupper，puppo have missing values </p>\n",
    "<p> combine doggo status column </p>\n",
    "<p> change the naming convention of doggo to first letter in upper case </p>\n",
    "<p> combine 'twitter archive enhanced'and 'tweet'two dataframes,inner join twitter id  </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# change stage \"none\" to blank\n",
    "tae_clean.doggo.replace('None', '', inplace=True)\n",
    "tae_clean.floofer.replace('None', '', inplace=True)\n",
    "tae_clean.pupper.replace('None', '', inplace=True)\n",
    "tae_clean.puppo.replace('None', '', inplace=True)\n",
    "tae_clean.sample(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#combine all stages to a single column called 'stage'\n",
    "tae_clean['dog_stage'] = tae_clean['doggo'] + tae_clean['floofer']+ tae_clean['pupper']+tae_clean['puppo']\n",
    "\n",
    "tae_clean.dog_stage.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
    "tae_clean.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename values in dog_stage column\n",
    "tae_clean.loc[tae_clean.dog_stage == 'pupper', 'dog_stage'] = 'Pupper'\n",
    "tae_clean.loc[tae_clean.dog_stage == 'doggo', 'dog_stage'] = 'Doggo'\n",
    "tae_clean.loc[tae_clean.dog_stage == 'puppo', 'dog_stage'] = 'Puppo'\n",
    "tae_clean.loc[tae_clean.dog_stage == 'doggopupper', 'dog_stage']= 'Doggo, Pupper'\n",
    "tae_clean.loc[tae_clean.dog_stage == 'floofer', 'dog_stage'] ='Floofer'\n",
    "tae_clean.loc[tae_clean.dog_stage == 'doggopuppo', 'dog_stage']= 'Doggo, Puppo'\n",
    "tae_clean.loc[tae_clean.dog_stage == 'doggofloofer', 'dog_stage'] = 'Doggo, Floofer'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace blank cells with NaNs\n",
    "tae_clean.loc[tae_clean.dog_stage == '', 'dog_stage'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace NaNs with text so we have non-null values\n",
    "tae_clean.dog_stage = tae_clean.dog_stage.fillna('Unknown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop unnecessary columns\n",
    "tae_clean.drop(['doggo', 'floofer', 'pupper', 'puppo'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Join the image_clean df to the twitter_archive_master df\n",
    "twitter_archive_master = pd.merge(tae_clean,tweet_clean,on='tweet_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
    "twitter_archive_master.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_archive_master.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Issue 3\n",
    "<p> there are pics that are not doggo</p>\n",
    "<p>some dogs names have no meaning</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new column for the dog prediction summary in image_prediction\n",
    "# first convert p1_dog, p2_dog, p3_dog to an integer \n",
    "prediction_summary = ['p1_dog', 'p2_dog', 'p3_dog']\n",
    "for p in prediction_summary:\n",
    "     ip_clean[p] = ip_clean[p].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new column that adds the total number of True and False for the 3 predictions\n",
    "ip_clean['prediction'] = ip_clean.p1_dog + ip_clean.p2_dog + ip_clean.p3_dog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace the number with a defining text string\n",
    "ip_clean['prediction'] = ip_clean['prediction'].replace(3, 'Dog')\n",
    "ip_clean['prediction'] = ip_clean['prediction'].replace(2, 'Maybe Dog')\n",
    "ip_clean['prediction'] = ip_clean['prediction'].replace(1, 'Maybe Dog')\n",
    "ip_clean['prediction'] = ip_clean['prediction'].replace(0, 'Not Dog')\n",
    "twitter_archive_master['name'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test\n",
    "ip_clean[['p1_dog', 'p2_dog', 'p3_dog','prediction']].sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert non-names to None\n",
    "twitter_archive_master['name'].str.lower()\n",
    "\n",
    "mask = (twitter_archive_master.name.str.islower())|(twitter_archive_master.name == 'None')\n",
    "\n",
    "twitter_archive_master.loc[mask, 'name'] = 'No_name'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_archive_master['name'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Issue 4\n",
    "<p> combine 'twitter archive enhanced', 'tweet', 'image prediction', these three dataframes，inner join twitter id </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Join the image_clean df to the twitter_archive_master df \n",
    "twitter_archive_master = pd.merge(twitter_archive_master, ip_clean, on='tweet_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test\n",
    "twitter_archive_master[['p1', 'p2', 'p3']].sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Issue 5\n",
    "<p> get rid of rows that are doggo </p>\n",
    "<p> get rid of underscores</p>\n",
    "<p> change 'timestamp' to 'datetime'</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove non-dogs from master dataset\n",
    "twitter_archive_master = twitter_archive_master[twitter_archive_master['prediction'] != \"Not Dog\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For predictions (p1, p2, p3), remove underscores and make title case.\n",
    "predictions = ['p1', 'p2', 'p3']\n",
    "for p in predictions:\n",
    "     twitter_archive_master[p] = twitter_archive_master[p].str.title().str.replace('_', \" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#change the type of timestamp to datetime\n",
    "twitter_archive_master['timestamp'] = pd.to_datetime(twitter_archive_master['timestamp'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_archive_master.info()\n",
    "twitter_archive_master.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Issue 6\n",
    "<p>the majority of denominators are 10, and some denominators are multiples of 10</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a rating column where the numerator is divided by denominator\n",
    "twitter_archive_master['rating'] = twitter_archive_master['rating_numerator']/twitter_archive_master['rating_denominator']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_archive_master.info()\n",
    "twitter_archive_master.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_archive_master.to_csv('twitter_archive_master.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot the relationship between favorite count and retweets\n",
    "sns.regplot(x=\"retweet_count\", y=\"favorite_count\", data=twitter_archive_master, scatter_kws={'alpha':0.2})\n",
    "plt.title('Retweet v. Favorite Count', size=16)\n",
    "plt.xlabel('Retweets', size=12)\n",
    "plt.ylabel('Favorites', size=12)\n",
    "plt.savefig('retweet-favorite.png');\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the most common stage of dogs\n",
    "twitter_archive_master['dog_stage'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ip_clean['prediction'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# conclusion\n",
    "\n",
    "#### there is a positive correlation between the favourites and retweets.\n",
    "#### pupper stage is the most common stage\n",
    "#### about 60% of the images are actually dogs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
